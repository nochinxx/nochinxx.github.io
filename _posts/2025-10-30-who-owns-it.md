---
layout: post
title: "Who Owns It? AI, App Development, and Intellectual Property"
date: 2025-10-30
tags: [ai, law, development, copyright, apps, intellectual-property]
excerpt: "AI can now write usable code in seconds—but who owns the final product? Here's how developers can navigate the creative and legal challenges of building with AI."
permalink: /posts/who-owns-it/
---

Artificial intelligence can now generate functional code in seconds, reducing the need for large engineering teams. Tools like GitHub Copilot and ChatGPT have made it possible for anyone with an idea to build an application—even without a computer science background. This democratization of development marks a revolutionary shift: **creativity, not coding ability, is now the true barrier to entry.**  

Yet as the power to create software becomes more accessible, the **legal and ethical boundaries of authorship and ownership** grow more uncertain. If an app is built with the help of AI, who owns the final product—the developer, the machine, or the company behind the tool?

---

## The New Reality of AI-Assisted Creation
Generative AI has lowered the technical barrier to entry, but the backbone of any good app still depends on design decisions and human intent. As Appel et al. write, *“Generative AI will change the nature of content creation, enabling many to do what, until now, only a few had the skills or technology to accomplish.”*  

From my own experience using Copilot and ChatGPT, this change feels like a balance between automation and authorship. Unclear prompts often produce messy or repetitive code, so I now focus first on refining my product’s structure and logic before generating anything. Unlike traditional development—where I would start small, mock a local database, and expand gradually—AI tools push me to think in broader design terms. My role shifts from writing every line to defining direction, like a designer guiding an assistant who writes in syntax.  

I see this transformation as similar to Tesla’s factories, where robots handle repetitive work while people focus on design and quality. In software creation, AI takes over mechanical coding tasks while developers refine vision and solve problems. But this progress raises an old question in a new form: **what does “ownership” mean when machines share in the creative process?**

---

## Where the Law Stands
Intellectual property (IP) law still centers on **human creativity.** It divides protection into four types:  
- **Copyright** – protects creative expression like code or design.  
- **Patent** – protects new inventions and must list a natural person as the inventor.  
- **Trademark** – protects brand names and logos.  
- **Trade secret** – protects confidential processes that give a competitive edge.  

When I built my latest app, [goalsforme.com](#), I wasn’t thinking about IP at all. Writing this paper made me realize that documentation and authorship are part of building responsibly. For developers, copyright is especially important: it safeguards the **interface, flow, and design choices** that make an app unique.  

Under U.S. law, only human authors can hold copyright. The *Thaler v. Perlmutter* case confirmed that “human authorship is an essential part of a valid copyright claim.” The U.S. Copyright Office has even rejected works lacking “meaningful human input.” In other words, unedited, fully AI-generated code cannot be copyrighted, but human modifications and organization of that code can. Those human edits become derivative works—and therefore protectable.

---

## The Benefits and the Risks
AI tools accelerate development and open the field to more people, but they also create new legal gray zones. Models trained on vast, sometimes unlicensed datasets may reproduce copyrighted material without attribution. That problem surfaced in the **GitHub Copilot** lawsuits, which claim the tool reused open-source code.  

As Bharati notes, “The implications of AI on IP rights are far reaching.” Legal systems worldwide are still deciding whether rights belong to the user, the model’s developer, or the data owners.  

From experience, I’ve learned that AI rarely writes perfect code. It often gives working snippets that need heavy editing to fit my project’s structure. I didn’t document those changes at first, but I now see that doing so is essential to prove authorship. AI also became an unexpected teacher—it showed me how the same logic could appear in Python before I rewrote it in TypeScript. That blend of correction and learning revealed how much of my work depends on **both human judgment and machine output.**

---

## Lessons for Developers
Writing this paper changed how I see AI as a creative partner. It made me more intentional about tracking generated code and corrections, since those details show where my contribution begins. AI helps bridge imagination and execution; it turns ideas that once stayed on my computer into products that reach people.  

To work responsibly with AI:  
1. **Document everything.** Record what the AI generated and what you changed.  
2. **Read the licenses** of the tools you use.  
3. **Add creativity.** Modify and expand generated code rather than using it unchanged.  
4. **Protect your brand** through copyright or trademarks.  
5. **Stay informed** as laws evolve.  

AI lowers barriers and speeds creation, but it also demands responsibility. The future of software belongs to those who combine **human vision with legal awareness**—because collaboration with AI does not erase originality; it demands clearer proof of it.

---

*Adapted from my essay “Who Owns It?” (CSC 300, San Francisco State University, 2025).*
[Download full essay (PDF)](/assets/documents/who-owns-it.pdf)

